{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwG5uxEpKaNL"
      },
      "source": [
        "# MMAI 894 - Exercise 2\n",
        "## Convolutional artificial neural network : Image classification\n",
        "The goal of this excercise is to build a convolutional neural network using the tensorflow/keras library. We will be using the MNIST dataset.\n",
        "Submission instructions:\n",
        "\n",
        "- You cannot edit this notebook directly. Save a copy to your drive, and make sure to identify yourself in the title using name and student number\n",
        "- Do not insert new cells before the final one (titled \"Further exploration\") \n",
        "- Verify that your notebook can _restart and run all_. \n",
        "- Select File -> Download as .py (important! not as ipynb)\n",
        "- Rename the file: `studentID_lastname_firstname_ex2.py`\n",
        "- The mark will be assessed on the implementation of the functions with #TODO\n",
        "- **Do not change anything outside the functions**  unless in the further exploration section\n",
        "- As you are encouraged to explore the network configuration, 20% of the mark is based on final accuracy. \n",
        "- Note: You do not have to answer the questions in thie notebook as part of your submission. They are meant to guide you.\n",
        "\n",
        "- You should not need to use any additional libraries other than the ones listed below. You may want to import additional modules from those libraries, however."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-DUt8ROKlvw"
      },
      "source": [
        "# Import modules\n",
        "# Add modules as needed\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# For windows laptops add following 2 lines:\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D,Flatten, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import argparse\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arrbzOo4LR9q"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "#### Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4wT7dbPLTNZ"
      },
      "source": [
        "def load_data():\n",
        "    # Import MNIST dataset from openml\n",
        "    dataset = fetch_openml('mnist_784', version=1, data_home=None, as_frame=False)\n",
        "\n",
        "    # Data preparation\n",
        "    raw_X = dataset['data']\n",
        "    raw_Y = dataset['target']\n",
        "    return raw_X, raw_Y\n",
        "\n",
        "raw_X, raw_Y = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRp1jQTrLc39"
      },
      "source": [
        "## Consider the following\n",
        "- Same as excercise 1\n",
        "- what shape should x be for a convolutional network?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mG0hdDRLZgD"
      },
      "source": [
        "def clean_data(raw_X, raw_Y):\n",
        "    # TODO: clean and QA raw_X and raw_Y\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    raw_X = (raw_X/255)\n",
        "\n",
        "    cleaned_X = tf.keras.utils.normalize(raw_X, axis=-1, order=1)\n",
        "    cleaned_Y = tf.keras.utils.to_categorical(raw_Y)\n",
        "    \n",
        "    return cleaned_X, cleaned_Y\n",
        "\n",
        "cleaned_X, cleaned_Y = clean_data(raw_X, raw_Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5OYgzj7NU_y"
      },
      "source": [
        "#### Data split\n",
        "\n",
        "- Split your data into a train set (50%), validation set (20%) and a test set (30%). You can use scikit-learn's train_test_split function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h7HIVDNNYap"
      },
      "source": [
        "def split_data(cleaned_X, cleaned_Y):\n",
        "    # TODO: split the data\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    train_ratio = 0.50\n",
        "    validation_ratio = 0.20\n",
        "    test_ratio = 0.30\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(cleaned_X, cleaned_Y, test_size = 1 - train_ratio)\n",
        "    X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
        "\n",
        "    \n",
        "    return X_val, X_test, X_train, Y_val, Y_test, Y_train\n",
        "\n",
        "X_val, X_test, X_train, Y_val, Y_test, Y_train = split_data(cleaned_X, cleaned_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY_z08TdNada"
      },
      "source": [
        "### Model\n",
        "\n",
        "#### Neural network structure\n",
        "\n",
        "This time, the exact model architecture is left to you to explore.  \n",
        "Keep the number of parameters below 2,000,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKAx26EDN3Yk"
      },
      "source": [
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "X_val = X_val.reshape(-1, 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "def build_model():\n",
        "    # TODO: build the model, \n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    model = models.Sequential()\n",
        "    model.add(Conv2D(120,\n",
        "    kernel_size=(3,3),\n",
        "    activation = 'relu',\n",
        "    input_shape=(28,28,1),\n",
        "    padding='same'))\n",
        "    \n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation = 'relu'))\n",
        "    model.add(Dense(10, activation ='softmax'))  \n",
        "    \n",
        "    return model\n",
        "\n",
        "def compile_model(model):\n",
        "    # TODO: compile the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy', \n",
        "              metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, Y_train, X_val, Y_val):\n",
        "    # TODO: train the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    history = model.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    batch_size=128,\n",
        "    epochs=12,\n",
        "    verbose=\"auto\",\n",
        "    validation_data=(X_val, Y_val)\n",
        "    )\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def eval_model(model, X_test, Y_test):\n",
        "    # TODO: evaluate the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    print(\"Evaluate on test data\")\n",
        "    results = model.evaluate(X_test, Y_test, batch_size=128)\n",
        "    print(\"test loss, test acc:\", results)\n",
        "    test_loss = results[0]\n",
        "    test_accuracy = results[1]\n",
        "\n",
        "    # Generate predictions (probabilities -- the output of the last layer)\n",
        "    # on new data using `predict`\n",
        "    print(\"Generate predictions for 3 samples\")\n",
        "    predictions = model.predict(X_test[:3])\n",
        "    print(\"predictions shape:\", predictions.shape)\n",
        "  \n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg5E9ChPOt_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f8e3c0-cb06-4af3-cebd-3ac825edeb22"
      },
      "source": [
        "## You may use this space (and add additional cells for exploration)\n",
        "\n",
        "model = build_model()\n",
        "model = compile_model(model)\n",
        "model, history = train_model(model, X_train, Y_train, X_val, Y_val)\n",
        "test_loss, test_accuracy = eval_model(model, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "274/274 [==============================] - 123s 448ms/step - loss: 0.8557 - accuracy: 0.7289 - val_loss: 0.3469 - val_accuracy: 0.8954\n",
            "Epoch 2/12\n",
            "274/274 [==============================] - 120s 437ms/step - loss: 0.2683 - accuracy: 0.9202 - val_loss: 0.1978 - val_accuracy: 0.9410\n",
            "Epoch 3/12\n",
            "274/274 [==============================] - 123s 448ms/step - loss: 0.1704 - accuracy: 0.9485 - val_loss: 0.1372 - val_accuracy: 0.9595\n",
            "Epoch 4/12\n",
            "274/274 [==============================] - 120s 437ms/step - loss: 0.1211 - accuracy: 0.9628 - val_loss: 0.1167 - val_accuracy: 0.9649\n",
            "Epoch 5/12\n",
            "274/274 [==============================] - 120s 438ms/step - loss: 0.0954 - accuracy: 0.9708 - val_loss: 0.0970 - val_accuracy: 0.9707\n",
            "Epoch 6/12\n",
            "274/274 [==============================] - 121s 442ms/step - loss: 0.0814 - accuracy: 0.9745 - val_loss: 0.0916 - val_accuracy: 0.9723\n",
            "Epoch 7/12\n",
            "274/274 [==============================] - 120s 438ms/step - loss: 0.0667 - accuracy: 0.9789 - val_loss: 0.0780 - val_accuracy: 0.9768\n",
            "Epoch 8/12\n",
            "274/274 [==============================] - 120s 439ms/step - loss: 0.0591 - accuracy: 0.9813 - val_loss: 0.0753 - val_accuracy: 0.9783\n",
            "Epoch 9/12\n",
            "274/274 [==============================] - 120s 439ms/step - loss: 0.0526 - accuracy: 0.9829 - val_loss: 0.0752 - val_accuracy: 0.9774\n",
            "Epoch 10/12\n",
            "274/274 [==============================] - 121s 440ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.0664 - val_accuracy: 0.9815\n",
            "Epoch 11/12\n",
            "274/274 [==============================] - 121s 440ms/step - loss: 0.0406 - accuracy: 0.9871 - val_loss: 0.0729 - val_accuracy: 0.9788\n",
            "Epoch 12/12\n",
            "274/274 [==============================] - 120s 439ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.0672 - val_accuracy: 0.9816\n",
            "Evaluate on test data\n",
            "165/165 [==============================] - 16s 98ms/step - loss: 0.0666 - accuracy: 0.9811\n",
            "test loss, test acc: [0.06664585322141647, 0.9811428785324097]\n",
            "Generate predictions for 3 samples\n",
            "predictions shape: (3, 10)\n"
          ]
        }
      ]
    }
  ]
}